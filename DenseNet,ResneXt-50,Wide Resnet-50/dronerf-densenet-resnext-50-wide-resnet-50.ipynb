{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b05d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:57:39.940218Z",
     "iopub.status.busy": "2025-04-13T16:57:39.939968Z",
     "iopub.status.idle": "2025-04-13T16:58:52.407698Z",
     "shell.execute_reply": "2025-04-13T16:58:52.406729Z"
    },
    "papermill": {
     "duration": 72.472515,
     "end_time": "2025-04-13T16:58:52.409304",
     "exception": false,
     "start_time": "2025-04-13T16:57:39.936789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thop\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.5.1+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\r\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\r\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8bfc5a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-13T16:58:52.447174Z",
     "iopub.status.busy": "2025-04-13T16:58:52.446811Z",
     "iopub.status.idle": "2025-04-13T20:20:45.634429Z",
     "shell.execute_reply": "2025-04-13T20:20:45.633427Z"
    },
    "papermill": {
     "duration": 12113.208402,
     "end_time": "2025-04-13T20:20:45.635969",
     "exception": false,
     "start_time": "2025-04-13T16:58:52.427567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total number of samples: 17744\n",
      "Class to index mapping: {'DJI': 0, 'FutabaT14': 1, 'FutabaT7': 2, 'Graupner': 3, 'Noise': 4, 'Taranis': 5, 'Turnigy': 6}\n",
      "Class DJI: 1280 samples\n",
      "Class FutabaT14: 3472 samples\n",
      "Class FutabaT7: 801 samples\n",
      "Class Graupner: 801 samples\n",
      "Class Noise: 8872 samples\n",
      "Class Taranis: 1663 samples\n",
      "Class Turnigy: 855 samples\n",
      "Number of classes: 7\n",
      "Class Names: ['DJI', 'FutabaT14', 'FutabaT7', 'Graupner', 'Noise', 'Taranis', 'Turnigy']\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING DENSENET-121\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 217MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating DenseNet-121\n",
      "==================================================\n",
      "\n",
      "DenseNet-121 Summary:\n",
      "Model Total Parameters: 6,961,031\n",
      "Trainable Parameters: 6,961,031\n",
      "\n",
      "Major layers:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer Name                               Type                 Parameters     \n",
      "--------------------------------------------------------------------------------\n",
      "features.conv0                           Conv2d               9,408\n",
      "features.norm0                           BatchNorm2d          128\n",
      "features.pool0                           MaxPool2d            0\n",
      "features.denseblock1.denselayer1.norm1   BatchNorm2d          128\n",
      "features.denseblock1.denselayer1.conv1   Conv2d               8,192\n",
      "features.denseblock1.denselayer1.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer1.conv2   Conv2d               36,864\n",
      "features.denseblock1.denselayer2.norm1   BatchNorm2d          192\n",
      "features.denseblock1.denselayer2.conv1   Conv2d               12,288\n",
      "features.denseblock1.denselayer2.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer2.conv2   Conv2d               36,864\n",
      "features.denseblock1.denselayer3.norm1   BatchNorm2d          256\n",
      "features.denseblock1.denselayer3.conv1   Conv2d               16,384\n",
      "features.denseblock1.denselayer3.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer3.conv2   Conv2d               36,864\n",
      "features.denseblock1.denselayer4.norm1   BatchNorm2d          320\n",
      "features.denseblock1.denselayer4.conv1   Conv2d               20,480\n",
      "features.denseblock1.denselayer4.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer4.conv2   Conv2d               36,864\n",
      "features.denseblock1.denselayer5.norm1   BatchNorm2d          384\n",
      "features.denseblock1.denselayer5.conv1   Conv2d               24,576\n",
      "features.denseblock1.denselayer5.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer5.conv2   Conv2d               36,864\n",
      "features.denseblock1.denselayer6.norm1   BatchNorm2d          448\n",
      "features.denseblock1.denselayer6.conv1   Conv2d               28,672\n",
      "features.denseblock1.denselayer6.norm2   BatchNorm2d          256\n",
      "features.denseblock1.denselayer6.conv2   Conv2d               36,864\n",
      "features.transition1.norm                BatchNorm2d          512\n",
      "features.transition1.conv                Conv2d               32,768\n",
      "features.denseblock2.denselayer1.norm1   BatchNorm2d          256\n",
      "features.denseblock2.denselayer1.conv1   Conv2d               16,384\n",
      "features.denseblock2.denselayer1.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer1.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer2.norm1   BatchNorm2d          320\n",
      "features.denseblock2.denselayer2.conv1   Conv2d               20,480\n",
      "features.denseblock2.denselayer2.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer2.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer3.norm1   BatchNorm2d          384\n",
      "features.denseblock2.denselayer3.conv1   Conv2d               24,576\n",
      "features.denseblock2.denselayer3.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer3.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer4.norm1   BatchNorm2d          448\n",
      "features.denseblock2.denselayer4.conv1   Conv2d               28,672\n",
      "features.denseblock2.denselayer4.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer4.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer5.norm1   BatchNorm2d          512\n",
      "features.denseblock2.denselayer5.conv1   Conv2d               32,768\n",
      "features.denseblock2.denselayer5.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer5.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer6.norm1   BatchNorm2d          576\n",
      "features.denseblock2.denselayer6.conv1   Conv2d               36,864\n",
      "features.denseblock2.denselayer6.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer6.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer7.norm1   BatchNorm2d          640\n",
      "features.denseblock2.denselayer7.conv1   Conv2d               40,960\n",
      "features.denseblock2.denselayer7.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer7.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer8.norm1   BatchNorm2d          704\n",
      "features.denseblock2.denselayer8.conv1   Conv2d               45,056\n",
      "features.denseblock2.denselayer8.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer8.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer9.norm1   BatchNorm2d          768\n",
      "features.denseblock2.denselayer9.conv1   Conv2d               49,152\n",
      "features.denseblock2.denselayer9.norm2   BatchNorm2d          256\n",
      "features.denseblock2.denselayer9.conv2   Conv2d               36,864\n",
      "features.denseblock2.denselayer10.norm1  BatchNorm2d          832\n",
      "features.denseblock2.denselayer10.conv1  Conv2d               53,248\n",
      "features.denseblock2.denselayer10.norm2  BatchNorm2d          256\n",
      "features.denseblock2.denselayer10.conv2  Conv2d               36,864\n",
      "features.denseblock2.denselayer11.norm1  BatchNorm2d          896\n",
      "features.denseblock2.denselayer11.conv1  Conv2d               57,344\n",
      "features.denseblock2.denselayer11.norm2  BatchNorm2d          256\n",
      "features.denseblock2.denselayer11.conv2  Conv2d               36,864\n",
      "features.denseblock2.denselayer12.norm1  BatchNorm2d          960\n",
      "features.denseblock2.denselayer12.conv1  Conv2d               61,440\n",
      "features.denseblock2.denselayer12.norm2  BatchNorm2d          256\n",
      "features.denseblock2.denselayer12.conv2  Conv2d               36,864\n",
      "features.transition2.norm                BatchNorm2d          1,024\n",
      "features.transition2.conv                Conv2d               131,072\n",
      "features.denseblock3.denselayer1.norm1   BatchNorm2d          512\n",
      "features.denseblock3.denselayer1.conv1   Conv2d               32,768\n",
      "features.denseblock3.denselayer1.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer1.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer2.norm1   BatchNorm2d          576\n",
      "features.denseblock3.denselayer2.conv1   Conv2d               36,864\n",
      "features.denseblock3.denselayer2.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer2.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer3.norm1   BatchNorm2d          640\n",
      "features.denseblock3.denselayer3.conv1   Conv2d               40,960\n",
      "features.denseblock3.denselayer3.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer3.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer4.norm1   BatchNorm2d          704\n",
      "features.denseblock3.denselayer4.conv1   Conv2d               45,056\n",
      "features.denseblock3.denselayer4.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer4.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer5.norm1   BatchNorm2d          768\n",
      "features.denseblock3.denselayer5.conv1   Conv2d               49,152\n",
      "features.denseblock3.denselayer5.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer5.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer6.norm1   BatchNorm2d          832\n",
      "features.denseblock3.denselayer6.conv1   Conv2d               53,248\n",
      "features.denseblock3.denselayer6.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer6.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer7.norm1   BatchNorm2d          896\n",
      "features.denseblock3.denselayer7.conv1   Conv2d               57,344\n",
      "features.denseblock3.denselayer7.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer7.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer8.norm1   BatchNorm2d          960\n",
      "features.denseblock3.denselayer8.conv1   Conv2d               61,440\n",
      "features.denseblock3.denselayer8.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer8.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer9.norm1   BatchNorm2d          1,024\n",
      "features.denseblock3.denselayer9.conv1   Conv2d               65,536\n",
      "features.denseblock3.denselayer9.norm2   BatchNorm2d          256\n",
      "features.denseblock3.denselayer9.conv2   Conv2d               36,864\n",
      "features.denseblock3.denselayer10.norm1  BatchNorm2d          1,088\n",
      "features.denseblock3.denselayer10.conv1  Conv2d               69,632\n",
      "features.denseblock3.denselayer10.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer10.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer11.norm1  BatchNorm2d          1,152\n",
      "features.denseblock3.denselayer11.conv1  Conv2d               73,728\n",
      "features.denseblock3.denselayer11.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer11.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer12.norm1  BatchNorm2d          1,216\n",
      "features.denseblock3.denselayer12.conv1  Conv2d               77,824\n",
      "features.denseblock3.denselayer12.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer12.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer13.norm1  BatchNorm2d          1,280\n",
      "features.denseblock3.denselayer13.conv1  Conv2d               81,920\n",
      "features.denseblock3.denselayer13.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer13.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer14.norm1  BatchNorm2d          1,344\n",
      "features.denseblock3.denselayer14.conv1  Conv2d               86,016\n",
      "features.denseblock3.denselayer14.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer14.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer15.norm1  BatchNorm2d          1,408\n",
      "features.denseblock3.denselayer15.conv1  Conv2d               90,112\n",
      "features.denseblock3.denselayer15.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer15.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer16.norm1  BatchNorm2d          1,472\n",
      "features.denseblock3.denselayer16.conv1  Conv2d               94,208\n",
      "features.denseblock3.denselayer16.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer16.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer17.norm1  BatchNorm2d          1,536\n",
      "features.denseblock3.denselayer17.conv1  Conv2d               98,304\n",
      "features.denseblock3.denselayer17.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer17.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer18.norm1  BatchNorm2d          1,600\n",
      "features.denseblock3.denselayer18.conv1  Conv2d               102,400\n",
      "features.denseblock3.denselayer18.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer18.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer19.norm1  BatchNorm2d          1,664\n",
      "features.denseblock3.denselayer19.conv1  Conv2d               106,496\n",
      "features.denseblock3.denselayer19.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer19.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer20.norm1  BatchNorm2d          1,728\n",
      "features.denseblock3.denselayer20.conv1  Conv2d               110,592\n",
      "features.denseblock3.denselayer20.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer20.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer21.norm1  BatchNorm2d          1,792\n",
      "features.denseblock3.denselayer21.conv1  Conv2d               114,688\n",
      "features.denseblock3.denselayer21.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer21.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer22.norm1  BatchNorm2d          1,856\n",
      "features.denseblock3.denselayer22.conv1  Conv2d               118,784\n",
      "features.denseblock3.denselayer22.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer22.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer23.norm1  BatchNorm2d          1,920\n",
      "features.denseblock3.denselayer23.conv1  Conv2d               122,880\n",
      "features.denseblock3.denselayer23.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer23.conv2  Conv2d               36,864\n",
      "features.denseblock3.denselayer24.norm1  BatchNorm2d          1,984\n",
      "features.denseblock3.denselayer24.conv1  Conv2d               126,976\n",
      "features.denseblock3.denselayer24.norm2  BatchNorm2d          256\n",
      "features.denseblock3.denselayer24.conv2  Conv2d               36,864\n",
      "features.transition3.norm                BatchNorm2d          2,048\n",
      "features.transition3.conv                Conv2d               524,288\n",
      "features.denseblock4.denselayer1.norm1   BatchNorm2d          1,024\n",
      "features.denseblock4.denselayer1.conv1   Conv2d               65,536\n",
      "features.denseblock4.denselayer1.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer1.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer2.norm1   BatchNorm2d          1,088\n",
      "features.denseblock4.denselayer2.conv1   Conv2d               69,632\n",
      "features.denseblock4.denselayer2.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer2.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer3.norm1   BatchNorm2d          1,152\n",
      "features.denseblock4.denselayer3.conv1   Conv2d               73,728\n",
      "features.denseblock4.denselayer3.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer3.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer4.norm1   BatchNorm2d          1,216\n",
      "features.denseblock4.denselayer4.conv1   Conv2d               77,824\n",
      "features.denseblock4.denselayer4.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer4.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer5.norm1   BatchNorm2d          1,280\n",
      "features.denseblock4.denselayer5.conv1   Conv2d               81,920\n",
      "features.denseblock4.denselayer5.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer5.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer6.norm1   BatchNorm2d          1,344\n",
      "features.denseblock4.denselayer6.conv1   Conv2d               86,016\n",
      "features.denseblock4.denselayer6.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer6.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer7.norm1   BatchNorm2d          1,408\n",
      "features.denseblock4.denselayer7.conv1   Conv2d               90,112\n",
      "features.denseblock4.denselayer7.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer7.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer8.norm1   BatchNorm2d          1,472\n",
      "features.denseblock4.denselayer8.conv1   Conv2d               94,208\n",
      "features.denseblock4.denselayer8.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer8.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer9.norm1   BatchNorm2d          1,536\n",
      "features.denseblock4.denselayer9.conv1   Conv2d               98,304\n",
      "features.denseblock4.denselayer9.norm2   BatchNorm2d          256\n",
      "features.denseblock4.denselayer9.conv2   Conv2d               36,864\n",
      "features.denseblock4.denselayer10.norm1  BatchNorm2d          1,600\n",
      "features.denseblock4.denselayer10.conv1  Conv2d               102,400\n",
      "features.denseblock4.denselayer10.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer10.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer11.norm1  BatchNorm2d          1,664\n",
      "features.denseblock4.denselayer11.conv1  Conv2d               106,496\n",
      "features.denseblock4.denselayer11.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer11.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer12.norm1  BatchNorm2d          1,728\n",
      "features.denseblock4.denselayer12.conv1  Conv2d               110,592\n",
      "features.denseblock4.denselayer12.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer12.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer13.norm1  BatchNorm2d          1,792\n",
      "features.denseblock4.denselayer13.conv1  Conv2d               114,688\n",
      "features.denseblock4.denselayer13.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer13.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer14.norm1  BatchNorm2d          1,856\n",
      "features.denseblock4.denselayer14.conv1  Conv2d               118,784\n",
      "features.denseblock4.denselayer14.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer14.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer15.norm1  BatchNorm2d          1,920\n",
      "features.denseblock4.denselayer15.conv1  Conv2d               122,880\n",
      "features.denseblock4.denselayer15.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer15.conv2  Conv2d               36,864\n",
      "features.denseblock4.denselayer16.norm1  BatchNorm2d          1,984\n",
      "features.denseblock4.denselayer16.conv1  Conv2d               126,976\n",
      "features.denseblock4.denselayer16.norm2  BatchNorm2d          256\n",
      "features.denseblock4.denselayer16.conv2  Conv2d               36,864\n",
      "features.norm5                           BatchNorm2d          2,048\n",
      "classifier                               Linear               7,175\n",
      "\n",
      "Model Structure:\n",
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=7, bias=True)\n",
      ")\n",
      "\n",
      "Starting training DenseNet-121...\n",
      "Epoch [1/50], Train Loss: 0.4535, Val Loss: 0.2536, Val Accuracy: 0.9372\n",
      "Model saved with validation accuracy: 0.9372\n",
      "Epoch [2/50], Train Loss: 0.2306, Val Loss: 0.2154, Val Accuracy: 0.9436\n",
      "Model saved with validation accuracy: 0.9436\n",
      "Epoch [3/50], Train Loss: 0.1859, Val Loss: 0.2003, Val Accuracy: 0.9504\n",
      "Model saved with validation accuracy: 0.9504\n",
      "Epoch [4/50], Train Loss: 0.1686, Val Loss: 0.3592, Val Accuracy: 0.9181\n",
      "Epoch [5/50], Train Loss: 0.1464, Val Loss: 0.1912, Val Accuracy: 0.9523\n",
      "Model saved with validation accuracy: 0.9523\n",
      "Epoch [6/50], Train Loss: 0.1329, Val Loss: 0.1963, Val Accuracy: 0.9485\n",
      "Epoch [7/50], Train Loss: 0.1074, Val Loss: 0.2087, Val Accuracy: 0.9500\n",
      "Epoch [8/50], Train Loss: 0.0969, Val Loss: 0.2336, Val Accuracy: 0.9463\n",
      "Epoch [9/50], Train Loss: 0.0907, Val Loss: 0.2151, Val Accuracy: 0.9504\n",
      "Epoch [10/50], Train Loss: 0.0459, Val Loss: 0.2039, Val Accuracy: 0.9545\n",
      "Model saved with validation accuracy: 0.9545\n",
      "Epoch [11/50], Train Loss: 0.0362, Val Loss: 0.2228, Val Accuracy: 0.9549\n",
      "Model saved with validation accuracy: 0.9549\n",
      "Epoch [12/50], Train Loss: 0.0222, Val Loss: 0.2230, Val Accuracy: 0.9557\n",
      "Model saved with validation accuracy: 0.9557\n",
      "Epoch [13/50], Train Loss: 0.0169, Val Loss: 0.2391, Val Accuracy: 0.9500\n",
      "Epoch [14/50], Train Loss: 0.0110, Val Loss: 0.2413, Val Accuracy: 0.9526\n",
      "Epoch [15/50], Train Loss: 0.0099, Val Loss: 0.2520, Val Accuracy: 0.9553\n",
      "Epoch [16/50], Train Loss: 0.0088, Val Loss: 0.2550, Val Accuracy: 0.9557\n",
      "Epoch [17/50], Train Loss: 0.0082, Val Loss: 0.2511, Val Accuracy: 0.9542\n",
      "Early stopping triggered after 17 epochs\n",
      "\n",
      "Evaluating DenseNet-121 on test set...\n",
      "\n",
      "DenseNet-121 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DJI       0.97      0.89      0.93       200\n",
      "   FutabaT14       0.98      0.89      0.93       548\n",
      "    FutabaT7       0.91      0.92      0.91        93\n",
      "    Graupner       1.00      0.99      1.00       107\n",
      "       Noise       0.94      0.99      0.96      1314\n",
      "     Taranis       1.00      0.99      0.99       268\n",
      "     Turnigy       1.00      0.97      0.98       133\n",
      "\n",
      "    accuracy                           0.96      2663\n",
      "   macro avg       0.97      0.95      0.96      2663\n",
      "weighted avg       0.96      0.96      0.96      2663\n",
      "\n",
      "\n",
      "DenseNet-121 Multi-class ROC AUC Score: 0.9914\n",
      "\n",
      "Analyzing DenseNet-121 performance by SNR levels...\n",
      "\n",
      "DenseNet-121 Performance by SNR level:\n",
      "SNR (dB) | Accuracy | Samples\n",
      "------------------------------\n",
      "\n",
      "DenseNet-121 Total Number of Parameters: 6,961,031\n",
      "DenseNet-121 Average Inference Time per Sample: 16.616 ms\n",
      "DenseNet-121 FLOPs: 2,895,990,272.0 (2.90 G)\n",
      "DenseNet-121 MACs: 6,961,031.0 (6.96 M)\n",
      "\n",
      "✅ DenseNet-121 Accuracy for class 'DJI': 88.50%\n",
      "✅ DenseNet-121 Accuracy for class 'FutabaT14': 88.87%\n",
      "✅ DenseNet-121 Accuracy for class 'FutabaT7': 92.47%\n",
      "✅ DenseNet-121 Accuracy for class 'Graupner': 99.07%\n",
      "✅ DenseNet-121 Accuracy for class 'Noise': 98.86%\n",
      "✅ DenseNet-121 Accuracy for class 'Taranis': 98.51%\n",
      "✅ DenseNet-121 Accuracy for class 'Turnigy': 96.99%\n",
      "\n",
      "✅ DenseNet-121 Test Set Accuracy: 0.957\n",
      "📊 DenseNet-121 Model Size: 26.55 MB\n",
      "\n",
      "Key characteristics of DenseNet-121:\n",
      "- Dense connectivity pattern with direct connections from any layer to all subsequent layers\n",
      "- Excellent feature reuse through dense connections\n",
      "- Requires fewer parameters due to feature reuse\n",
      "- Good performance with reduced overfitting\n",
      "- Efficient gradient flow during training\n",
      "\n",
      "Metrics saved to densenet_121_drone_rf_metrics.json\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING RESNEXT-50\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|██████████| 95.8M/95.8M [00:00<00:00, 206MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating ResNeXt-50\n",
      "==================================================\n",
      "\n",
      "ResNeXt-50 Summary:\n",
      "Model Total Parameters: 22,994,247\n",
      "Trainable Parameters: 22,994,247\n",
      "\n",
      "Major layers:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer Name                               Type                 Parameters     \n",
      "--------------------------------------------------------------------------------\n",
      "conv1                                    Conv2d               9,408\n",
      "bn1                                      BatchNorm2d          128\n",
      "maxpool                                  MaxPool2d            0\n",
      "layer1.0.conv1                           Conv2d               8,192\n",
      "layer1.0.bn1                             BatchNorm2d          256\n",
      "layer1.0.conv2                           Conv2d               4,608\n",
      "layer1.0.bn2                             BatchNorm2d          256\n",
      "layer1.0.conv3                           Conv2d               32,768\n",
      "layer1.0.bn3                             BatchNorm2d          512\n",
      "layer1.0.downsample.0                    Conv2d               16,384\n",
      "layer1.0.downsample.1                    BatchNorm2d          512\n",
      "layer1.1.conv1                           Conv2d               32,768\n",
      "layer1.1.bn1                             BatchNorm2d          256\n",
      "layer1.1.conv2                           Conv2d               4,608\n",
      "layer1.1.bn2                             BatchNorm2d          256\n",
      "layer1.1.conv3                           Conv2d               32,768\n",
      "layer1.1.bn3                             BatchNorm2d          512\n",
      "layer1.2.conv1                           Conv2d               32,768\n",
      "layer1.2.bn1                             BatchNorm2d          256\n",
      "layer1.2.conv2                           Conv2d               4,608\n",
      "layer1.2.bn2                             BatchNorm2d          256\n",
      "layer1.2.conv3                           Conv2d               32,768\n",
      "layer1.2.bn3                             BatchNorm2d          512\n",
      "layer2.0.conv1                           Conv2d               65,536\n",
      "layer2.0.bn1                             BatchNorm2d          512\n",
      "layer2.0.conv2                           Conv2d               18,432\n",
      "layer2.0.bn2                             BatchNorm2d          512\n",
      "layer2.0.conv3                           Conv2d               131,072\n",
      "layer2.0.bn3                             BatchNorm2d          1,024\n",
      "layer2.0.downsample.0                    Conv2d               131,072\n",
      "layer2.0.downsample.1                    BatchNorm2d          1,024\n",
      "layer2.1.conv1                           Conv2d               131,072\n",
      "layer2.1.bn1                             BatchNorm2d          512\n",
      "layer2.1.conv2                           Conv2d               18,432\n",
      "layer2.1.bn2                             BatchNorm2d          512\n",
      "layer2.1.conv3                           Conv2d               131,072\n",
      "layer2.1.bn3                             BatchNorm2d          1,024\n",
      "layer2.2.conv1                           Conv2d               131,072\n",
      "layer2.2.bn1                             BatchNorm2d          512\n",
      "layer2.2.conv2                           Conv2d               18,432\n",
      "layer2.2.bn2                             BatchNorm2d          512\n",
      "layer2.2.conv3                           Conv2d               131,072\n",
      "layer2.2.bn3                             BatchNorm2d          1,024\n",
      "layer2.3.conv1                           Conv2d               131,072\n",
      "layer2.3.bn1                             BatchNorm2d          512\n",
      "layer2.3.conv2                           Conv2d               18,432\n",
      "layer2.3.bn2                             BatchNorm2d          512\n",
      "layer2.3.conv3                           Conv2d               131,072\n",
      "layer2.3.bn3                             BatchNorm2d          1,024\n",
      "layer3.0.conv1                           Conv2d               262,144\n",
      "layer3.0.bn1                             BatchNorm2d          1,024\n",
      "layer3.0.conv2                           Conv2d               73,728\n",
      "layer3.0.bn2                             BatchNorm2d          1,024\n",
      "layer3.0.conv3                           Conv2d               524,288\n",
      "layer3.0.bn3                             BatchNorm2d          2,048\n",
      "layer3.0.downsample.0                    Conv2d               524,288\n",
      "layer3.0.downsample.1                    BatchNorm2d          2,048\n",
      "layer3.1.conv1                           Conv2d               524,288\n",
      "layer3.1.bn1                             BatchNorm2d          1,024\n",
      "layer3.1.conv2                           Conv2d               73,728\n",
      "layer3.1.bn2                             BatchNorm2d          1,024\n",
      "layer3.1.conv3                           Conv2d               524,288\n",
      "layer3.1.bn3                             BatchNorm2d          2,048\n",
      "layer3.2.conv1                           Conv2d               524,288\n",
      "layer3.2.bn1                             BatchNorm2d          1,024\n",
      "layer3.2.conv2                           Conv2d               73,728\n",
      "layer3.2.bn2                             BatchNorm2d          1,024\n",
      "layer3.2.conv3                           Conv2d               524,288\n",
      "layer3.2.bn3                             BatchNorm2d          2,048\n",
      "layer3.3.conv1                           Conv2d               524,288\n",
      "layer3.3.bn1                             BatchNorm2d          1,024\n",
      "layer3.3.conv2                           Conv2d               73,728\n",
      "layer3.3.bn2                             BatchNorm2d          1,024\n",
      "layer3.3.conv3                           Conv2d               524,288\n",
      "layer3.3.bn3                             BatchNorm2d          2,048\n",
      "layer3.4.conv1                           Conv2d               524,288\n",
      "layer3.4.bn1                             BatchNorm2d          1,024\n",
      "layer3.4.conv2                           Conv2d               73,728\n",
      "layer3.4.bn2                             BatchNorm2d          1,024\n",
      "layer3.4.conv3                           Conv2d               524,288\n",
      "layer3.4.bn3                             BatchNorm2d          2,048\n",
      "layer3.5.conv1                           Conv2d               524,288\n",
      "layer3.5.bn1                             BatchNorm2d          1,024\n",
      "layer3.5.conv2                           Conv2d               73,728\n",
      "layer3.5.bn2                             BatchNorm2d          1,024\n",
      "layer3.5.conv3                           Conv2d               524,288\n",
      "layer3.5.bn3                             BatchNorm2d          2,048\n",
      "layer4.0.conv1                           Conv2d               1,048,576\n",
      "layer4.0.bn1                             BatchNorm2d          2,048\n",
      "layer4.0.conv2                           Conv2d               294,912\n",
      "layer4.0.bn2                             BatchNorm2d          2,048\n",
      "layer4.0.conv3                           Conv2d               2,097,152\n",
      "layer4.0.bn3                             BatchNorm2d          4,096\n",
      "layer4.0.downsample.0                    Conv2d               2,097,152\n",
      "layer4.0.downsample.1                    BatchNorm2d          4,096\n",
      "layer4.1.conv1                           Conv2d               2,097,152\n",
      "layer4.1.bn1                             BatchNorm2d          2,048\n",
      "layer4.1.conv2                           Conv2d               294,912\n",
      "layer4.1.bn2                             BatchNorm2d          2,048\n",
      "layer4.1.conv3                           Conv2d               2,097,152\n",
      "layer4.1.bn3                             BatchNorm2d          4,096\n",
      "layer4.2.conv1                           Conv2d               2,097,152\n",
      "layer4.2.bn1                             BatchNorm2d          2,048\n",
      "layer4.2.conv2                           Conv2d               294,912\n",
      "layer4.2.bn2                             BatchNorm2d          2,048\n",
      "layer4.2.conv3                           Conv2d               2,097,152\n",
      "layer4.2.bn3                             BatchNorm2d          4,096\n",
      "avgpool                                  AdaptiveAvgPool2d    0\n",
      "fc                                       Linear               14,343\n",
      "\n",
      "Model Structure:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
      ")\n",
      "\n",
      "Starting training ResNeXt-50...\n",
      "Epoch [1/50], Train Loss: 0.4044, Val Loss: 0.2136, Val Accuracy: 0.9455\n",
      "Model saved with validation accuracy: 0.9455\n",
      "Epoch [2/50], Train Loss: 0.2401, Val Loss: 0.2164, Val Accuracy: 0.9481\n",
      "Model saved with validation accuracy: 0.9481\n",
      "Epoch [3/50], Train Loss: 0.1809, Val Loss: 0.2053, Val Accuracy: 0.9511\n",
      "Model saved with validation accuracy: 0.9511\n",
      "Epoch [4/50], Train Loss: 0.1808, Val Loss: 0.1755, Val Accuracy: 0.9568\n",
      "Model saved with validation accuracy: 0.9568\n",
      "Epoch [5/50], Train Loss: 0.1524, Val Loss: 0.1933, Val Accuracy: 0.9504\n",
      "Epoch [6/50], Train Loss: 0.1326, Val Loss: 0.2129, Val Accuracy: 0.9463\n",
      "Epoch [7/50], Train Loss: 0.1288, Val Loss: 0.1915, Val Accuracy: 0.9530\n",
      "Epoch [8/50], Train Loss: 0.1151, Val Loss: 0.2233, Val Accuracy: 0.9466\n",
      "Epoch [9/50], Train Loss: 0.0696, Val Loss: 0.1967, Val Accuracy: 0.9545\n",
      "Early stopping triggered after 9 epochs\n",
      "\n",
      "Evaluating ResNeXt-50 on test set...\n",
      "\n",
      "ResNeXt-50 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DJI       0.98      0.88      0.92       200\n",
      "   FutabaT14       0.96      0.90      0.93       548\n",
      "    FutabaT7       0.98      0.92      0.95        93\n",
      "    Graupner       0.99      0.98      0.99       107\n",
      "       Noise       0.94      0.99      0.96      1314\n",
      "     Taranis       1.00      0.99      0.99       268\n",
      "     Turnigy       1.00      0.97      0.98       133\n",
      "\n",
      "    accuracy                           0.96      2663\n",
      "   macro avg       0.98      0.95      0.96      2663\n",
      "weighted avg       0.96      0.96      0.96      2663\n",
      "\n",
      "\n",
      "ResNeXt-50 Multi-class ROC AUC Score: 0.9911\n",
      "\n",
      "Analyzing ResNeXt-50 performance by SNR levels...\n",
      "\n",
      "ResNeXt-50 Performance by SNR level:\n",
      "SNR (dB) | Accuracy | Samples\n",
      "------------------------------\n",
      "\n",
      "ResNeXt-50 Total Number of Parameters: 22,994,247\n",
      "ResNeXt-50 Average Inference Time per Sample: 7.946 ms\n",
      "ResNeXt-50 FLOPs: 4,286,150,656.0 (4.29 G)\n",
      "ResNeXt-50 MACs: 22,994,247.0 (22.99 M)\n",
      "\n",
      "✅ ResNeXt-50 Accuracy for class 'DJI': 87.50%\n",
      "✅ ResNeXt-50 Accuracy for class 'FutabaT14': 89.78%\n",
      "✅ ResNeXt-50 Accuracy for class 'FutabaT7': 92.47%\n",
      "✅ ResNeXt-50 Accuracy for class 'Graupner': 98.13%\n",
      "✅ ResNeXt-50 Accuracy for class 'Noise': 98.71%\n",
      "✅ ResNeXt-50 Accuracy for class 'Taranis': 98.51%\n",
      "✅ ResNeXt-50 Accuracy for class 'Turnigy': 96.99%\n",
      "\n",
      "✅ ResNeXt-50 Test Set Accuracy: 0.957\n",
      "📊 ResNeXt-50 Model Size: 87.72 MB\n",
      "\n",
      "Key characteristics of ResNeXt-50:\n",
      "- Extension of ResNet that aggregates residual transformations\n",
      "- Uses split-transform-merge strategy with grouped convolutions\n",
      "- Better performance than ResNet with similar complexity\n",
      "- Higher accuracy-to-computation ratio than many models\n",
      "- Cardinality dimension provides a more effective way to adjust model capacity\n",
      "\n",
      "Metrics saved to resnext_50_drone_rf_metrics.json\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TRAINING WIDE RESNET-50\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
      "100%|██████████| 132M/132M [00:01<00:00, 138MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating Wide ResNet-50\n",
      "==================================================\n",
      "\n",
      "Wide ResNet-50 Summary:\n",
      "Model Total Parameters: 66,848,583\n",
      "Trainable Parameters: 66,848,583\n",
      "\n",
      "Major layers:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer Name                               Type                 Parameters     \n",
      "--------------------------------------------------------------------------------\n",
      "conv1                                    Conv2d               9,408\n",
      "bn1                                      BatchNorm2d          128\n",
      "maxpool                                  MaxPool2d            0\n",
      "layer1.0.conv1                           Conv2d               8,192\n",
      "layer1.0.bn1                             BatchNorm2d          256\n",
      "layer1.0.conv2                           Conv2d               147,456\n",
      "layer1.0.bn2                             BatchNorm2d          256\n",
      "layer1.0.conv3                           Conv2d               32,768\n",
      "layer1.0.bn3                             BatchNorm2d          512\n",
      "layer1.0.downsample.0                    Conv2d               16,384\n",
      "layer1.0.downsample.1                    BatchNorm2d          512\n",
      "layer1.1.conv1                           Conv2d               32,768\n",
      "layer1.1.bn1                             BatchNorm2d          256\n",
      "layer1.1.conv2                           Conv2d               147,456\n",
      "layer1.1.bn2                             BatchNorm2d          256\n",
      "layer1.1.conv3                           Conv2d               32,768\n",
      "layer1.1.bn3                             BatchNorm2d          512\n",
      "layer1.2.conv1                           Conv2d               32,768\n",
      "layer1.2.bn1                             BatchNorm2d          256\n",
      "layer1.2.conv2                           Conv2d               147,456\n",
      "layer1.2.bn2                             BatchNorm2d          256\n",
      "layer1.2.conv3                           Conv2d               32,768\n",
      "layer1.2.bn3                             BatchNorm2d          512\n",
      "layer2.0.conv1                           Conv2d               65,536\n",
      "layer2.0.bn1                             BatchNorm2d          512\n",
      "layer2.0.conv2                           Conv2d               589,824\n",
      "layer2.0.bn2                             BatchNorm2d          512\n",
      "layer2.0.conv3                           Conv2d               131,072\n",
      "layer2.0.bn3                             BatchNorm2d          1,024\n",
      "layer2.0.downsample.0                    Conv2d               131,072\n",
      "layer2.0.downsample.1                    BatchNorm2d          1,024\n",
      "layer2.1.conv1                           Conv2d               131,072\n",
      "layer2.1.bn1                             BatchNorm2d          512\n",
      "layer2.1.conv2                           Conv2d               589,824\n",
      "layer2.1.bn2                             BatchNorm2d          512\n",
      "layer2.1.conv3                           Conv2d               131,072\n",
      "layer2.1.bn3                             BatchNorm2d          1,024\n",
      "layer2.2.conv1                           Conv2d               131,072\n",
      "layer2.2.bn1                             BatchNorm2d          512\n",
      "layer2.2.conv2                           Conv2d               589,824\n",
      "layer2.2.bn2                             BatchNorm2d          512\n",
      "layer2.2.conv3                           Conv2d               131,072\n",
      "layer2.2.bn3                             BatchNorm2d          1,024\n",
      "layer2.3.conv1                           Conv2d               131,072\n",
      "layer2.3.bn1                             BatchNorm2d          512\n",
      "layer2.3.conv2                           Conv2d               589,824\n",
      "layer2.3.bn2                             BatchNorm2d          512\n",
      "layer2.3.conv3                           Conv2d               131,072\n",
      "layer2.3.bn3                             BatchNorm2d          1,024\n",
      "layer3.0.conv1                           Conv2d               262,144\n",
      "layer3.0.bn1                             BatchNorm2d          1,024\n",
      "layer3.0.conv2                           Conv2d               2,359,296\n",
      "layer3.0.bn2                             BatchNorm2d          1,024\n",
      "layer3.0.conv3                           Conv2d               524,288\n",
      "layer3.0.bn3                             BatchNorm2d          2,048\n",
      "layer3.0.downsample.0                    Conv2d               524,288\n",
      "layer3.0.downsample.1                    BatchNorm2d          2,048\n",
      "layer3.1.conv1                           Conv2d               524,288\n",
      "layer3.1.bn1                             BatchNorm2d          1,024\n",
      "layer3.1.conv2                           Conv2d               2,359,296\n",
      "layer3.1.bn2                             BatchNorm2d          1,024\n",
      "layer3.1.conv3                           Conv2d               524,288\n",
      "layer3.1.bn3                             BatchNorm2d          2,048\n",
      "layer3.2.conv1                           Conv2d               524,288\n",
      "layer3.2.bn1                             BatchNorm2d          1,024\n",
      "layer3.2.conv2                           Conv2d               2,359,296\n",
      "layer3.2.bn2                             BatchNorm2d          1,024\n",
      "layer3.2.conv3                           Conv2d               524,288\n",
      "layer3.2.bn3                             BatchNorm2d          2,048\n",
      "layer3.3.conv1                           Conv2d               524,288\n",
      "layer3.3.bn1                             BatchNorm2d          1,024\n",
      "layer3.3.conv2                           Conv2d               2,359,296\n",
      "layer3.3.bn2                             BatchNorm2d          1,024\n",
      "layer3.3.conv3                           Conv2d               524,288\n",
      "layer3.3.bn3                             BatchNorm2d          2,048\n",
      "layer3.4.conv1                           Conv2d               524,288\n",
      "layer3.4.bn1                             BatchNorm2d          1,024\n",
      "layer3.4.conv2                           Conv2d               2,359,296\n",
      "layer3.4.bn2                             BatchNorm2d          1,024\n",
      "layer3.4.conv3                           Conv2d               524,288\n",
      "layer3.4.bn3                             BatchNorm2d          2,048\n",
      "layer3.5.conv1                           Conv2d               524,288\n",
      "layer3.5.bn1                             BatchNorm2d          1,024\n",
      "layer3.5.conv2                           Conv2d               2,359,296\n",
      "layer3.5.bn2                             BatchNorm2d          1,024\n",
      "layer3.5.conv3                           Conv2d               524,288\n",
      "layer3.5.bn3                             BatchNorm2d          2,048\n",
      "layer4.0.conv1                           Conv2d               1,048,576\n",
      "layer4.0.bn1                             BatchNorm2d          2,048\n",
      "layer4.0.conv2                           Conv2d               9,437,184\n",
      "layer4.0.bn2                             BatchNorm2d          2,048\n",
      "layer4.0.conv3                           Conv2d               2,097,152\n",
      "layer4.0.bn3                             BatchNorm2d          4,096\n",
      "layer4.0.downsample.0                    Conv2d               2,097,152\n",
      "layer4.0.downsample.1                    BatchNorm2d          4,096\n",
      "layer4.1.conv1                           Conv2d               2,097,152\n",
      "layer4.1.bn1                             BatchNorm2d          2,048\n",
      "layer4.1.conv2                           Conv2d               9,437,184\n",
      "layer4.1.bn2                             BatchNorm2d          2,048\n",
      "layer4.1.conv3                           Conv2d               2,097,152\n",
      "layer4.1.bn3                             BatchNorm2d          4,096\n",
      "layer4.2.conv1                           Conv2d               2,097,152\n",
      "layer4.2.bn1                             BatchNorm2d          2,048\n",
      "layer4.2.conv2                           Conv2d               9,437,184\n",
      "layer4.2.bn2                             BatchNorm2d          2,048\n",
      "layer4.2.conv3                           Conv2d               2,097,152\n",
      "layer4.2.bn3                             BatchNorm2d          4,096\n",
      "avgpool                                  AdaptiveAvgPool2d    0\n",
      "fc                                       Linear               14,343\n",
      "\n",
      "Model Structure:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
      ")\n",
      "\n",
      "Starting training Wide ResNet-50...\n",
      "Epoch [1/50], Train Loss: 0.4637, Val Loss: 0.2872, Val Accuracy: 0.9278\n",
      "Model saved with validation accuracy: 0.9278\n",
      "Epoch [2/50], Train Loss: 0.2705, Val Loss: 0.3285, Val Accuracy: 0.9252\n",
      "Epoch [3/50], Train Loss: 0.2172, Val Loss: 0.2273, Val Accuracy: 0.9429\n",
      "Model saved with validation accuracy: 0.9429\n",
      "Epoch [4/50], Train Loss: 0.2034, Val Loss: 0.1897, Val Accuracy: 0.9534\n",
      "Model saved with validation accuracy: 0.9534\n",
      "Epoch [5/50], Train Loss: 0.1856, Val Loss: 0.2170, Val Accuracy: 0.9474\n",
      "Epoch [6/50], Train Loss: 0.1644, Val Loss: 0.1949, Val Accuracy: 0.9511\n",
      "Epoch [7/50], Train Loss: 0.1508, Val Loss: 0.2147, Val Accuracy: 0.9500\n",
      "Epoch [8/50], Train Loss: 0.1445, Val Loss: 0.1942, Val Accuracy: 0.9542\n",
      "Model saved with validation accuracy: 0.9542\n",
      "Epoch [9/50], Train Loss: 0.1007, Val Loss: 0.1861, Val Accuracy: 0.9553\n",
      "Model saved with validation accuracy: 0.9553\n",
      "Epoch [10/50], Train Loss: 0.0802, Val Loss: 0.1875, Val Accuracy: 0.9549\n",
      "Epoch [11/50], Train Loss: 0.0643, Val Loss: 0.2058, Val Accuracy: 0.9568\n",
      "Model saved with validation accuracy: 0.9568\n",
      "Epoch [12/50], Train Loss: 0.0479, Val Loss: 0.2246, Val Accuracy: 0.9523\n",
      "Epoch [13/50], Train Loss: 0.0327, Val Loss: 0.2453, Val Accuracy: 0.9511\n",
      "Epoch [14/50], Train Loss: 0.0211, Val Loss: 0.2577, Val Accuracy: 0.9523\n",
      "Epoch [15/50], Train Loss: 0.0169, Val Loss: 0.2579, Val Accuracy: 0.9496\n",
      "Epoch [16/50], Train Loss: 0.0156, Val Loss: 0.2923, Val Accuracy: 0.9534\n",
      "Early stopping triggered after 16 epochs\n",
      "\n",
      "Evaluating Wide ResNet-50 on test set...\n",
      "\n",
      "Wide ResNet-50 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DJI       0.98      0.87      0.92       200\n",
      "   FutabaT14       0.96      0.90      0.93       548\n",
      "    FutabaT7       1.00      0.92      0.96        93\n",
      "    Graupner       1.00      0.98      0.99       107\n",
      "       Noise       0.94      0.99      0.96      1314\n",
      "     Taranis       1.00      0.99      0.99       268\n",
      "     Turnigy       0.99      0.96      0.98       133\n",
      "\n",
      "    accuracy                           0.96      2663\n",
      "   macro avg       0.98      0.94      0.96      2663\n",
      "weighted avg       0.96      0.96      0.96      2663\n",
      "\n",
      "\n",
      "Wide ResNet-50 Multi-class ROC AUC Score: 0.9892\n",
      "\n",
      "Analyzing Wide ResNet-50 performance by SNR levels...\n",
      "\n",
      "Wide ResNet-50 Performance by SNR level:\n",
      "SNR (dB) | Accuracy | Samples\n",
      "------------------------------\n",
      "\n",
      "Wide ResNet-50 Total Number of Parameters: 66,848,583\n",
      "Wide ResNet-50 Average Inference Time per Sample: 7.828 ms\n",
      "Wide ResNet-50 FLOPs: 11,453,691,904.0 (11.45 G)\n",
      "Wide ResNet-50 MACs: 66,848,583.0 (66.85 M)\n",
      "\n",
      "✅ Wide ResNet-50 Accuracy for class 'DJI': 87.00%\n",
      "✅ Wide ResNet-50 Accuracy for class 'FutabaT14': 89.96%\n",
      "✅ Wide ResNet-50 Accuracy for class 'FutabaT7': 92.47%\n",
      "✅ Wide ResNet-50 Accuracy for class 'Graupner': 98.13%\n",
      "✅ Wide ResNet-50 Accuracy for class 'Noise': 98.78%\n",
      "✅ Wide ResNet-50 Accuracy for class 'Taranis': 98.51%\n",
      "✅ Wide ResNet-50 Accuracy for class 'Turnigy': 96.24%\n",
      "\n",
      "✅ Wide ResNet-50 Test Set Accuracy: 0.957\n",
      "📊 Wide ResNet-50 Model Size: 255.01 MB\n",
      "\n",
      "Key characteristics of Wide ResNet-50:\n",
      "- Modification of ResNet with increased width (channel count) and reduced depth\n",
      "- Wider networks often achieve better performance than deeper ones\n",
      "- More efficient to train than very deep networks\n",
      "- Better feature extraction capability with wider channels\n",
      "- Strong classification performance with reasonable computational cost\n",
      "\n",
      "Metrics saved to wide resnet_50_drone_rf_metrics.json\n",
      "\n",
      "\n",
      "All models have been trained and evaluated!\n",
      "Results have been saved to individual files for each model.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# Helper function for formatting large numbers\n",
    "def format_units(num):\n",
    "    \"\"\"Format large numbers with units (K, M, G, etc.)\"\"\"\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    return f\"{num:.2f} {['', 'K', 'M', 'G', 'T', 'P'][magnitude]}\"\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16\n",
    "standard_img_size = 224  # Standard size for most models (DenseNet, ResNeXt, Wide ResNet)\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-4\n",
    "split_ratio = [0.7, 0.15, 0.15]  # 70% training, 15% validation, 15% test\n",
    "\n",
    "# Dataset Directory\n",
    "dataset_dir = \"/kaggle/input/drone-data/clean_spectrograms\"\n",
    "\n",
    "# Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((standard_img_size, standard_img_size)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB if needed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to create data loaders with proper dataset splits and consistent indices\n",
    "def create_data_loaders(full_dataset):\n",
    "    # Get a generator with fixed seed for consistent splits\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    \n",
    "    # Split into Train, Validation, and Test\n",
    "    train_size = int(split_ratio[0] * len(full_dataset))\n",
    "    val_size = int(split_ratio[1] * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size, test_size],\n",
    "        generator=generator\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Load Full Dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_data_loaders(full_dataset)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Total number of samples: {len(full_dataset)}\")\n",
    "class_to_idx = full_dataset.class_to_idx\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "for class_name, idx in class_to_idx.items():\n",
    "    class_samples = len([x for x, y in full_dataset.samples if y == idx])\n",
    "    print(f\"Class {class_name}: {class_samples} samples\")\n",
    "\n",
    "# Number of Classes\n",
    "num_classes = len(full_dataset.classes)\n",
    "class_names = full_dataset.classes\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "\n",
    "# Function to extract SNR from filename\n",
    "def extract_snr(filename):\n",
    "    try:\n",
    "        # Assuming filename format like \"sample_0_snr_-14.png\"\n",
    "        parts = os.path.basename(filename).split('_')\n",
    "        snr_idx = parts.index('snr') + 1\n",
    "        return int(parts[snr_idx])\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "# Custom model summary function that works with any architecture\n",
    "def get_model_summary(model, input_size=(1, 3, 224, 224)):\n",
    "    \"\"\"\n",
    "    A custom function to generate model summary that works with all architectures.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        input_size: Input tensor size (batch_size, channels, height, width)\n",
    "        \n",
    "    Returns:\n",
    "        model_info: String with model information\n",
    "    \"\"\"\n",
    "    model_info = \"\"\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    model_info += f\"Model Total Parameters: {total_params:,}\\n\"\n",
    "    model_info += f\"Trainable Parameters: {trainable_params:,}\\n\\n\"\n",
    "    \n",
    "    # Try to get layer info without causing errors\n",
    "    try:\n",
    "        # Create a dummy input\n",
    "        x = torch.rand(input_size).to(next(model.parameters()).device)\n",
    "        \n",
    "        # Calculate output size by recording the output of each module\n",
    "        with torch.no_grad():\n",
    "            module_names = []\n",
    "            module_list = []\n",
    "            \n",
    "            # For non-sequential models, get important modules\n",
    "            for name, module in model.named_modules():\n",
    "                if isinstance(module, (nn.Conv2d, nn.Linear, nn.BatchNorm2d, nn.MaxPool2d, nn.AdaptiveAvgPool2d)) and \\\n",
    "                   not any(name.startswith(n + \".\") for n in module_names):\n",
    "                    module_names.append(name)\n",
    "                    module_list.append(module)\n",
    "            \n",
    "            # Display major layers\n",
    "            model_info += \"Major layers:\\n\"\n",
    "            model_info += \"-\" * 80 + \"\\n\"\n",
    "            model_info += f\"{'Layer Name':<40} {'Type':<20} {'Parameters':<15}\\n\"\n",
    "            model_info += \"-\" * 80 + \"\\n\"\n",
    "            \n",
    "            for name, module in zip(module_names, module_list):\n",
    "                params = sum(p.numel() for p in module.parameters())\n",
    "                model_info += f\"{name:<40} {module.__class__.__name__:<20} {params:,}\\n\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        model_info += f\"Could not generate detailed layer information due to: {str(e)}\\n\"\n",
    "        \n",
    "    # Add model structure\n",
    "    model_info += \"\\nModel Structure:\\n\"\n",
    "    model_info += str(model)\n",
    "    \n",
    "    return model_info\n",
    "        \n",
    "# Define a function to train and evaluate a model\n",
    "def train_and_evaluate_model(model_name, model, train_loader, val_loader, test_loader, test_dataset, full_dataset):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training and Evaluating {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print model summary using our custom function\n",
    "    print(f\"\\n{model_name} Summary:\")\n",
    "    print(get_model_summary(model, input_size=(1, 3, standard_img_size, standard_img_size)))\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "    \n",
    "    # Training Loop\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    early_stop_counter = 0\n",
    "    early_stop_patience = 5\n",
    "    best_model_weights = None\n",
    "    \n",
    "    print(f\"\\nStarting training {model_name}...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), f\"{model_name.lower().replace('-', '_')}_drone_rf.pth\")\n",
    "            print(f\"Model saved with validation accuracy: {val_accuracy:.4f}\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} - Loss Over Epochs')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} - Accuracy Over Epochs')\n",
    "    plt.savefig(f\"{model_name.lower().replace('-', '_')}_drone_rf_training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Load the best model for evaluation\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing the Model\n",
    "    print(f\"\\nEvaluating {model_name} on test set...\")\n",
    "    y_true, y_pred, y_scores = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_scores.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "    \n",
    "    # Classification Report\n",
    "    cls_report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.savefig(f\"{model_name.lower().replace('-', '_')}_drone_rf_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # ROC Curve (for multi-class classification)\n",
    "    roc_auc = None\n",
    "    if num_classes > 2:\n",
    "        y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "        y_scores_array = np.array(y_scores)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true_bin, y_scores_array, multi_class=\"ovr\")\n",
    "        print(f\"\\n{model_name} Multi-class ROC AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i in range(num_classes):\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores_array[:, i])\n",
    "            auc_score = roc_auc_score(y_true_bin[:, i], y_scores_array[:, i])\n",
    "            plt.plot(fpr, tpr, label=f\"Class {class_names[i]} (AUC = {auc_score:.2f})\")\n",
    "    \n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"{model_name} ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{model_name.lower().replace('-', '_')}_drone_rf_roc_curve.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # SNR-based performance analysis\n",
    "    print(f\"\\nAnalyzing {model_name} performance by SNR levels...\")\n",
    "    \n",
    "    # Create a dictionary to store predictions by SNR\n",
    "    snr_results = {}\n",
    "    \n",
    "    # Re-run through test dataset to get filenames and predictions\n",
    "    test_dataset_files = [full_dataset.samples[i][0] for i in test_dataset.indices]\n",
    "    test_dataset_labels = [full_dataset.samples[i][1] for i in test_dataset.indices]\n",
    "    \n",
    "    # Match predictions with SNR values\n",
    "    for i, (file_path, true_label) in enumerate(zip(test_dataset_files, test_dataset_labels)):\n",
    "        snr = extract_snr(file_path)\n",
    "        if snr is not None:\n",
    "            if snr not in snr_results:\n",
    "                snr_results[snr] = {'correct': 0, 'total': 0}\n",
    "            snr_results[snr]['total'] += 1\n",
    "            if y_pred[i] == y_true[i]:\n",
    "                snr_results[snr]['correct'] += 1\n",
    "    \n",
    "    # Calculate accuracy by SNR\n",
    "    snr_accuracy = {snr: results['correct'] / results['total'] \n",
    "                    for snr, results in snr_results.items() if results['total'] > 0}\n",
    "    \n",
    "    # Plot SNR vs. Accuracy\n",
    "    sorted_snrs = sorted(snr_accuracy.keys())\n",
    "    accuracies = [snr_accuracy[snr] for snr in sorted_snrs]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sorted_snrs, accuracies, 'o-')\n",
    "    plt.xlabel('Signal-to-Noise Ratio (dB)')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    plt.title(f'{model_name} Performance vs. Signal-to-Noise Ratio')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{model_name.lower().replace('-', '_')}_drone_rf_snr_performance.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Print SNR performance table\n",
    "    print(f\"\\n{model_name} Performance by SNR level:\")\n",
    "    print(\"SNR (dB) | Accuracy | Samples\")\n",
    "    print(\"-\" * 30)\n",
    "    snr_table = []\n",
    "    for snr in sorted_snrs:\n",
    "        acc = snr_accuracy[snr]\n",
    "        samples = snr_results[snr]['total']\n",
    "        print(f\"{snr:7d} | {acc:.4f} | {samples}\")\n",
    "        snr_table.append({\"snr\": snr, \"accuracy\": acc, \"samples\": samples})\n",
    "    \n",
    "    # Inference Time Calculation\n",
    "    sample_input = torch.randn(1, 3, standard_img_size, standard_img_size).to(device)\n",
    "    num_samples = 100\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            _ = model(sample_input)\n",
    "    inference_time = (time.time() - start_time) / num_samples\n",
    "    \n",
    "    # Number of Parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # FLOPs & MACs Calculation\n",
    "    try:\n",
    "        from thop import profile\n",
    "        flops, macs = profile(model, inputs=(sample_input,), verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating FLOPs and MACs: {str(e)}\")\n",
    "        flops, macs = 0, 0\n",
    "    \n",
    "    # Convert inference time to milliseconds\n",
    "    inference_time_ms = inference_time * 1000\n",
    "    \n",
    "    print(f\"\\n{model_name} Total Number of Parameters: {num_params:,}\")\n",
    "    print(f\"{model_name} Average Inference Time per Sample: {inference_time_ms:.3f} ms\")\n",
    "    print(f\"{model_name} FLOPs: {flops:,} ({format_units(flops)})\")\n",
    "    print(f\"{model_name} MACs: {macs:,} ({format_units(macs)})\\n\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "    class_acc_dict = {}\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(f\"✅ {model_name} Accuracy for class '{class_names[i]}': {acc:.2%}\")\n",
    "        class_acc_dict[class_names[i]] = float(acc)\n",
    "    \n",
    "    # Calculate and display test accuracy with 3 decimal places\n",
    "    test_correct = sum([1 for i, j in zip(y_true, y_pred) if i == j])\n",
    "    test_total = len(y_true)\n",
    "    test_accuracy = test_correct / test_total\n",
    "    print(f\"\\n✅ {model_name} Test Set Accuracy: {test_accuracy:.3f}\")\n",
    "    \n",
    "    # Calculate and display model size in MB\n",
    "    # Each parameter is typically stored as a 32-bit float (4 bytes)\n",
    "    model_size_bytes = num_params * 4\n",
    "    model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "    print(f\"📊 {model_name} Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Model characteristics based on model name\n",
    "    characteristics = []\n",
    "    if model_name == \"DenseNet-121\":\n",
    "        characteristics = [\n",
    "            \"Dense connectivity pattern with direct connections from any layer to all subsequent layers\",\n",
    "            \"Excellent feature reuse through dense connections\",\n",
    "            \"Requires fewer parameters due to feature reuse\",\n",
    "            \"Good performance with reduced overfitting\",\n",
    "            \"Efficient gradient flow during training\"\n",
    "        ]\n",
    "    elif model_name == \"ResNeXt-50\":\n",
    "        characteristics = [\n",
    "            \"Extension of ResNet that aggregates residual transformations\",\n",
    "            \"Uses split-transform-merge strategy with grouped convolutions\",\n",
    "            \"Better performance than ResNet with similar complexity\",\n",
    "            \"Higher accuracy-to-computation ratio than many models\",\n",
    "            \"Cardinality dimension provides a more effective way to adjust model capacity\"\n",
    "        ]\n",
    "    elif model_name == \"Wide ResNet-50\":\n",
    "        characteristics = [\n",
    "            \"Modification of ResNet with increased width (channel count) and reduced depth\",\n",
    "            \"Wider networks often achieve better performance than deeper ones\",\n",
    "            \"More efficient to train than very deep networks\",\n",
    "            \"Better feature extraction capability with wider channels\",\n",
    "            \"Strong classification performance with reasonable computational cost\"\n",
    "        ]\n",
    "    \n",
    "    # Print characteristics\n",
    "    print(f\"\\nKey characteristics of {model_name}:\")\n",
    "    for char in characteristics:\n",
    "        print(f\"- {char}\")\n",
    "    \n",
    "    # Save all metrics to a JSON file\n",
    "    metrics = {\n",
    "        \"model_name\": model_name,\n",
    "        \"test_accuracy\": float(test_accuracy),\n",
    "        \"inference_time_ms\": float(inference_time_ms),\n",
    "        \"model_size_mb\": float(model_size_mb),\n",
    "        \"parameters\": int(num_params),\n",
    "        \"flops\": int(flops),\n",
    "        \"macs\": int(macs),\n",
    "        \"roc_auc_score\": float(roc_auc) if roc_auc is not None else None,\n",
    "        \"per_class_accuracy\": class_acc_dict,\n",
    "        \"snr_performance\": snr_table,\n",
    "        \"classification_report\": cls_report,\n",
    "        \"characteristics\": characteristics\n",
    "    }\n",
    "    \n",
    "    with open(f\"{model_name.lower().replace('-', '_')}_drone_rf_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nMetrics saved to {model_name.lower().replace('-', '_')}_drone_rf_metrics.json\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and train models sequentially\n",
    "\n",
    "# 1. DenseNet-121\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TRAINING DENSENET-121\")\n",
    "print(\"=\"*80)\n",
    "densenet = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
    "densenet.classifier = nn.Linear(densenet.classifier.in_features, num_classes)\n",
    "train_and_evaluate_model('DenseNet-121', densenet, train_loader, val_loader, test_loader, test_dataset, full_dataset)\n",
    "\n",
    "# 2. ResNeXt-50\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TRAINING RESNEXT-50\")\n",
    "print(\"=\"*80)\n",
    "resnext = models.resnext50_32x4d(weights=\"IMAGENET1K_V1\")\n",
    "resnext.fc = nn.Linear(resnext.fc.in_features, num_classes)\n",
    "train_and_evaluate_model('ResNeXt-50', resnext, train_loader, val_loader, test_loader, test_dataset, full_dataset)\n",
    "\n",
    "# 3. Wide ResNet-50\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TRAINING WIDE RESNET-50\")\n",
    "print(\"=\"*80)\n",
    "wide_resnet = models.wide_resnet50_2(weights=\"IMAGENET1K_V1\")\n",
    "wide_resnet.fc = nn.Linear(wide_resnet.fc.in_features, num_classes)\n",
    "train_and_evaluate_model('Wide ResNet-50', wide_resnet, train_loader, val_loader, test_loader, test_dataset, full_dataset)\n",
    "\n",
    "print(\"\\n\\nAll models have been trained and evaluated!\")\n",
    "print(\"Results have been saved to individual files for each model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e456e",
   "metadata": {
    "papermill": {
     "duration": 0.024291,
     "end_time": "2025-04-13T20:20:45.684317",
     "exception": false,
     "start_time": "2025-04-13T20:20:45.660026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 233589092,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12193.067315,
   "end_time": "2025-04-13T20:20:48.684701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T16:57:35.617386",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
